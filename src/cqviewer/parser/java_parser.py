"""Parse Java source and class files to extract field definitions.

This module can read either:
- .java source files: Parses field declarations from source code
- .class bytecode files: Reads field info from compiled class files

Supports auto-detection of encoding format:
- Thrift: Detected by org.apache.thrift.TBase or TField patterns
- SBE: Detected by uk.co.real_logic.sbe or @SbeField patterns
- Binary: Default for simple POJOs

No external dependencies required - uses only Python standard library.
"""

import re
import struct
from dataclasses import dataclass, field
from pathlib import Path
from typing import BinaryIO

from .schema import Schema, MessageDef, FieldDef, ENCODING_BINARY, ENCODING_THRIFT, ENCODING_SBE


# Java type to schema type mapping
JAVA_TYPE_MAP = {
    # Primitives
    "byte": "int8",
    "short": "int16",
    "int": "int32",
    "long": "int64",
    "float": "float32",
    "double": "float64",
    "boolean": "bool",
    "char": "uint16",
    # Common wrapper types (treated same as primitives for binary format)
    "Byte": "int8",
    "Short": "int16",
    "Integer": "int32",
    "Long": "int64",
    "Float": "float32",
    "Double": "float64",
    "Boolean": "bool",
    "Character": "uint16",
    # String types
    "String": "string",
    "CharSequence": "string",
    # Binary
    "byte[]": "bytes",
}

# JVM type descriptors to schema types
JVM_TYPE_MAP = {
    "B": "int8",    # byte
    "C": "uint16",  # char
    "D": "float64", # double
    "F": "float32", # float
    "I": "int32",   # int
    "J": "int64",   # long
    "S": "int16",   # short
    "Z": "bool",    # boolean
}


@dataclass
class JavaField:
    """Represents a field extracted from Java source or bytecode."""
    name: str
    java_type: str
    is_static: bool = False
    is_transient: bool = False
    field_id: int | None = None  # Thrift field ID (1-based)


def parse_java_source(filepath: str | Path) -> tuple[str | None, list[JavaField], str]:
    """Parse a .java source file to extract class name, field declarations, and encoding.

    Args:
        filepath: Path to .java file

    Returns:
        Tuple of (class_name, list of JavaField objects, encoding)
    """
    filepath = Path(filepath)
    content = filepath.read_text(encoding="utf-8")

    fields = []

    # Detect encoding before removing comments (to catch comment markers like "Autogenerated by Thrift")
    detected_encoding = detect_encoding_from_source(content)

    # Extract Thrift field IDs if this is a Thrift class
    thrift_field_ids = {}
    if detected_encoding == ENCODING_THRIFT:
        thrift_field_ids = extract_thrift_field_ids(content)

    # Remove comments
    content_no_comments = re.sub(r"//.*$", "", content, flags=re.MULTILINE)
    content_no_comments = re.sub(r"/\*.*?\*/", "", content_no_comments, flags=re.DOTALL)

    # Extract class name
    class_pattern = re.compile(r"\bclass\s+(\w+)")
    class_match = class_pattern.search(content_no_comments)
    class_name = class_match.group(1) if class_match else None

    # Find the class body - content between first { after class declaration and matching }
    class_body = None
    if class_match:
        class_start = class_match.end()
        # Find opening brace
        brace_pos = content_no_comments.find("{", class_start)
        if brace_pos != -1:
            # Find matching closing brace (track nesting)
            depth = 1
            pos = brace_pos + 1
            while pos < len(content_no_comments) and depth > 0:
                if content_no_comments[pos] == "{":
                    depth += 1
                elif content_no_comments[pos] == "}":
                    depth -= 1
                pos += 1
            class_body = content_no_comments[brace_pos + 1:pos - 1]

    if not class_body:
        return class_name, fields

    # Remove method bodies to avoid picking up local variables
    # Find methods by looking for patterns like: type name(...) { ... }
    # We'll remove everything between method { } braces
    def remove_method_bodies(text: str) -> str:
        result = []
        i = 0
        while i < len(text):
            # Look for method pattern: ) followed by optional throws, then {
            if text[i] == ')':
                # Check if this is followed by { (possibly with throws clause)
                j = i + 1
                while j < len(text) and text[j] in ' \t\n\r':
                    j += 1
                # Skip throws clause
                if j < len(text) - 6 and text[j:j+6] == 'throws':
                    while j < len(text) and text[j] != '{':
                        j += 1
                # Check for {
                if j < len(text) and text[j] == '{':
                    # Skip method body
                    result.append(text[i])  # Keep the )
                    depth = 1
                    j += 1
                    while j < len(text) and depth > 0:
                        if text[j] == '{':
                            depth += 1
                        elif text[j] == '}':
                            depth -= 1
                        j += 1
                    i = j
                    continue
            result.append(text[i])
            i += 1
        return ''.join(result)

    # Also remove inner classes and enums
    def remove_inner_classes(text: str) -> str:
        # Remove enum blocks
        text = re.sub(r'\benum\s+\w+\s*\{[^}]*\}', '', text, flags=re.DOTALL)
        # Remove inner class blocks
        text = re.sub(r'\bclass\s+\w+[^{]*\{[^}]*\}', '', text, flags=re.DOTALL)
        return text

    cleaned_body = remove_method_bodies(class_body)
    cleaned_body = remove_inner_classes(cleaned_body)

    # Now extract field declarations from cleaned class body
    # Look for: [modifiers] [annotations] type fieldName [= value];
    # Handle patterns like: public @Nullable String fieldName;

    field_pattern = re.compile(
        r"""
        ^\s*                                    # Start of line
        (public|private|protected)              # Access modifier (required)
        ((?:\s+(?:static|final|volatile|transient))*)  # Other modifiers (capture all together)
        \s+
        (?:@[\w.]+(?:\([^)]*\))?\s+)*           # Inline annotations (like @Nullable)
        ([\w\[\]<>,.]+)                         # Type (simpler match)
        \s+
        (\w+)                                   # Field name
        \s*
        (?:=[^;]*)?                             # Optional initializer
        \s*;                                    # Semicolon
        """,
        re.VERBOSE | re.MULTILINE
    )

    seen_fields = set()
    for match in field_pattern.finditer(cleaned_body):
        access = match.group(1) or ""
        other_mods = match.group(2) or ""
        java_type = match.group(3).strip()
        name = match.group(4)

        # Skip duplicates
        if name in seen_fields:
            continue
        seen_fields.add(name)

        modifiers = access + other_mods
        is_static = "static" in modifiers
        is_transient = "transient" in modifiers

        # Clean up type - remove generics, get simple name
        java_type = re.sub(r"<.*>", "", java_type)
        # Get the simple type name (last part after dots)
        java_type = java_type.strip().split(".")[-1].strip()

        # Skip if type looks invalid
        if not java_type or java_type in ("void", "class", "interface", "enum"):
            continue

        # Get Thrift field ID if available
        field_id = thrift_field_ids.get(name)

        fields.append(JavaField(
            name=name,
            java_type=java_type,
            is_static=is_static,
            is_transient=is_transient,
            field_id=field_id,
        ))

    return class_name, fields, detected_encoding


def detect_encoding_from_source(content: str) -> str:
    """Detect encoding format from Java source content.

    NOTE: Thrift-generated Java classes are often serialized using Chronicle's
    BINARY_LIGHT format, not Thrift TCompactProtocol, when used with Chronicle Queue.
    We default to BINARY_LIGHT unless explicitly overridden with --encoding thrift.

    Args:
        content: Java source code content

    Returns:
        Encoding format: ENCODING_THRIFT, ENCODING_SBE, or ENCODING_BINARY
    """
    # SBE detection patterns - these are more reliable
    sbe_patterns = [
        r"uk\.co\.real_logic\.sbe",
        r"@SbeField",
        r"MessageHeaderEncoder",
        r"MessageHeaderDecoder",
    ]

    for pattern in sbe_patterns:
        if re.search(pattern, content):
            return ENCODING_SBE

    # Note: Thrift-generated classes are NOT auto-detected as Thrift encoding
    # because Chronicle Queue typically serializes them using BINARY_LIGHT format.
    # Use --encoding thrift to force Thrift TCompactProtocol decoding.

    return ENCODING_BINARY


def extract_thrift_field_ids(content: str) -> dict[str, int]:
    """Extract Thrift field IDs from Java source.

    Looks for TField declarations like:
        new TField("fieldName", TType.STRING, (short)2)

    Args:
        content: Java source code content

    Returns:
        Dictionary mapping field names to their Thrift field IDs
    """
    field_ids = {}

    # Pattern to match TField declarations
    # e.g.: new org.apache.thrift.protocol.TField("appId", org.apache.thrift.protocol.TType.STRING, (short)2)
    tfield_pattern = re.compile(
        r'new\s+(?:org\.apache\.thrift\.protocol\.)?TField\s*\(\s*'
        r'"(\w+)"\s*,\s*'  # Field name
        r'(?:org\.apache\.thrift\.protocol\.)?TType\.(\w+)\s*,\s*'  # Type
        r'\(short\)\s*(\d+)\s*\)',  # Field ID
        re.IGNORECASE
    )

    for match in tfield_pattern.finditer(content):
        field_name = match.group(1)
        field_id = int(match.group(3))
        field_ids[field_name] = field_id

    return field_ids


def parse_java_class(filepath: str | Path) -> tuple[str, list[JavaField]]:
    """Parse a .class bytecode file to extract field information.

    Args:
        filepath: Path to .class file

    Returns:
        Tuple of (class_name, list of JavaField objects)
    """
    filepath = Path(filepath)

    with open(filepath, "rb") as f:
        return _parse_class_file(f)


def _parse_class_file(f: BinaryIO) -> tuple[str, list[JavaField]]:
    """Parse Java class file format.

    Reference: https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html
    """
    # Magic number
    magic = struct.unpack(">I", f.read(4))[0]
    if magic != 0xCAFEBABE:
        raise ValueError("Not a valid Java class file")

    # Version
    minor_version = struct.unpack(">H", f.read(2))[0]
    major_version = struct.unpack(">H", f.read(2))[0]

    # Constant pool
    constant_pool_count = struct.unpack(">H", f.read(2))[0]
    constant_pool = _read_constant_pool(f, constant_pool_count)

    # Access flags
    access_flags = struct.unpack(">H", f.read(2))[0]

    # This class
    this_class = struct.unpack(">H", f.read(2))[0]
    class_name = _resolve_class_name(constant_pool, this_class)

    # Super class
    super_class = struct.unpack(">H", f.read(2))[0]

    # Interfaces
    interfaces_count = struct.unpack(">H", f.read(2))[0]
    f.read(2 * interfaces_count)  # Skip interface indices

    # Fields
    fields_count = struct.unpack(">H", f.read(2))[0]
    fields = []

    for _ in range(fields_count):
        field = _read_field(f, constant_pool)
        if field:
            fields.append(field)

    return class_name, fields


def _read_constant_pool(f: BinaryIO, count: int) -> list:
    """Read the constant pool from class file."""
    # Index 0 is unused, so we start with a placeholder
    pool = [None]

    i = 1
    while i < count:
        tag = struct.unpack(">B", f.read(1))[0]

        if tag == 1:  # CONSTANT_Utf8
            length = struct.unpack(">H", f.read(2))[0]
            value = f.read(length).decode("utf-8", errors="replace")
            pool.append(("Utf8", value))
        elif tag == 3:  # CONSTANT_Integer
            value = struct.unpack(">i", f.read(4))[0]
            pool.append(("Integer", value))
        elif tag == 4:  # CONSTANT_Float
            value = struct.unpack(">f", f.read(4))[0]
            pool.append(("Float", value))
        elif tag == 5:  # CONSTANT_Long
            value = struct.unpack(">q", f.read(8))[0]
            pool.append(("Long", value))
            pool.append(None)  # Long takes two slots
            i += 1
        elif tag == 6:  # CONSTANT_Double
            value = struct.unpack(">d", f.read(8))[0]
            pool.append(("Double", value))
            pool.append(None)  # Double takes two slots
            i += 1
        elif tag == 7:  # CONSTANT_Class
            name_index = struct.unpack(">H", f.read(2))[0]
            pool.append(("Class", name_index))
        elif tag == 8:  # CONSTANT_String
            string_index = struct.unpack(">H", f.read(2))[0]
            pool.append(("String", string_index))
        elif tag == 9:  # CONSTANT_Fieldref
            class_index = struct.unpack(">H", f.read(2))[0]
            name_type_index = struct.unpack(">H", f.read(2))[0]
            pool.append(("Fieldref", class_index, name_type_index))
        elif tag == 10:  # CONSTANT_Methodref
            class_index = struct.unpack(">H", f.read(2))[0]
            name_type_index = struct.unpack(">H", f.read(2))[0]
            pool.append(("Methodref", class_index, name_type_index))
        elif tag == 11:  # CONSTANT_InterfaceMethodref
            class_index = struct.unpack(">H", f.read(2))[0]
            name_type_index = struct.unpack(">H", f.read(2))[0]
            pool.append(("InterfaceMethodref", class_index, name_type_index))
        elif tag == 12:  # CONSTANT_NameAndType
            name_index = struct.unpack(">H", f.read(2))[0]
            descriptor_index = struct.unpack(">H", f.read(2))[0]
            pool.append(("NameAndType", name_index, descriptor_index))
        elif tag == 15:  # CONSTANT_MethodHandle
            reference_kind = struct.unpack(">B", f.read(1))[0]
            reference_index = struct.unpack(">H", f.read(2))[0]
            pool.append(("MethodHandle", reference_kind, reference_index))
        elif tag == 16:  # CONSTANT_MethodType
            descriptor_index = struct.unpack(">H", f.read(2))[0]
            pool.append(("MethodType", descriptor_index))
        elif tag == 17:  # CONSTANT_Dynamic
            bootstrap_method_attr_index = struct.unpack(">H", f.read(2))[0]
            name_type_index = struct.unpack(">H", f.read(2))[0]
            pool.append(("Dynamic", bootstrap_method_attr_index, name_type_index))
        elif tag == 18:  # CONSTANT_InvokeDynamic
            bootstrap_method_attr_index = struct.unpack(">H", f.read(2))[0]
            name_type_index = struct.unpack(">H", f.read(2))[0]
            pool.append(("InvokeDynamic", bootstrap_method_attr_index, name_type_index))
        elif tag == 19:  # CONSTANT_Module
            name_index = struct.unpack(">H", f.read(2))[0]
            pool.append(("Module", name_index))
        elif tag == 20:  # CONSTANT_Package
            name_index = struct.unpack(">H", f.read(2))[0]
            pool.append(("Package", name_index))
        else:
            raise ValueError(f"Unknown constant pool tag: {tag}")

        i += 1

    return pool


def _resolve_class_name(pool: list, index: int) -> str:
    """Resolve a class name from constant pool."""
    entry = pool[index]
    if entry and entry[0] == "Class":
        name_entry = pool[entry[1]]
        if name_entry and name_entry[0] == "Utf8":
            # Convert internal format (com/example/Class) to simple name
            full_name = name_entry[1]
            return full_name.split("/")[-1]
    return "Unknown"


def _read_field(f: BinaryIO, constant_pool: list) -> JavaField | None:
    """Read a single field from class file."""
    access_flags = struct.unpack(">H", f.read(2))[0]
    name_index = struct.unpack(">H", f.read(2))[0]
    descriptor_index = struct.unpack(">H", f.read(2))[0]
    attributes_count = struct.unpack(">H", f.read(2))[0]

    # Skip attributes
    for _ in range(attributes_count):
        attr_name_index = struct.unpack(">H", f.read(2))[0]
        attr_length = struct.unpack(">I", f.read(4))[0]
        f.read(attr_length)

    # Get field name
    name_entry = constant_pool[name_index]
    if not name_entry or name_entry[0] != "Utf8":
        return None
    name = name_entry[1]

    # Get field type descriptor
    desc_entry = constant_pool[descriptor_index]
    if not desc_entry or desc_entry[0] != "Utf8":
        return None
    descriptor = desc_entry[1]

    # Parse access flags
    ACC_STATIC = 0x0008
    ACC_TRANSIENT = 0x0080

    is_static = bool(access_flags & ACC_STATIC)
    is_transient = bool(access_flags & ACC_TRANSIENT)

    # Convert descriptor to Java type
    java_type = _descriptor_to_type(descriptor)

    return JavaField(
        name=name,
        java_type=java_type,
        is_static=is_static,
        is_transient=is_transient,
    )


def _descriptor_to_type(descriptor: str) -> str:
    """Convert JVM type descriptor to Java type name."""
    if not descriptor:
        return "unknown"

    # Array
    if descriptor.startswith("["):
        element_type = _descriptor_to_type(descriptor[1:])
        return f"{element_type}[]"

    # Primitive
    if descriptor in JVM_TYPE_MAP:
        # Return the Java name, not schema type
        java_names = {
            "B": "byte", "C": "char", "D": "double", "F": "float",
            "I": "int", "J": "long", "S": "short", "Z": "boolean",
        }
        return java_names.get(descriptor, descriptor)

    # Object type: Lcom/example/ClassName;
    if descriptor.startswith("L") and descriptor.endswith(";"):
        class_name = descriptor[1:-1]
        # Return simple class name
        return class_name.split("/")[-1]

    return "unknown"


def java_type_to_schema_type(java_type: str) -> str:
    """Convert Java type to schema type.

    Args:
        java_type: Java type name (e.g., "long", "String", "double")

    Returns:
        Schema type (e.g., "int64", "string", "float64")
    """
    # Check direct mapping
    if java_type in JAVA_TYPE_MAP:
        return JAVA_TYPE_MAP[java_type]

    # Array of bytes
    if java_type == "byte[]":
        return "bytes"

    # Other arrays - treat as bytes for now
    if java_type.endswith("[]"):
        return "bytes"

    # Unknown object types - likely nested structs
    # Mark as "object" so the decoder can try to handle them
    return "object"


def java_fields_to_schema(
    class_name: str,
    fields: list[JavaField],
    include_static: bool = False,
    include_transient: bool = False,
    encoding: str | None = None,
) -> Schema:
    """Convert Java fields to a Schema.

    Args:
        class_name: Name of the Java class
        fields: List of JavaField objects
        include_static: Whether to include static fields
        include_transient: Whether to include transient fields
        encoding: Encoding format (auto-detected if None)

    Returns:
        Schema object
    """
    schema_fields = []

    for field in fields:
        # Skip static fields (they're not serialized)
        if field.is_static and not include_static:
            continue

        # Skip transient fields (they're not serialized)
        if field.is_transient and not include_transient:
            continue

        # Skip internal Thrift/SBE fields
        if field.name.startswith('_') or field.name.startswith('__'):
            continue

        schema_type = java_type_to_schema_type(field.java_type)

        schema_fields.append(FieldDef(
            name=field.name,
            type=schema_type,
            field_id=field.field_id,
        ))

    message_def = MessageDef(name=class_name, fields=schema_fields)

    # Use provided encoding or default to binary
    if encoding is None:
        encoding = ENCODING_BINARY

    return Schema(
        messages={class_name: message_def},
        default_message=class_name,
        encoding=encoding,
    )


def parse_java_file(filepath: str | Path, encoding: str | None = None) -> Schema:
    """Parse a .java or .class file and return a Schema.

    Args:
        filepath: Path to .java or .class file
        encoding: Force specific encoding (auto-detected if None)

    Returns:
        Schema object with field definitions
    """
    filepath = Path(filepath)

    if filepath.suffix == ".java":
        # Parse source file
        class_name, fields, detected_encoding = parse_java_source(filepath)
        # Fall back to filename if class name not found
        if not class_name:
            class_name = filepath.stem
        # Use provided encoding or auto-detected
        final_encoding = encoding if encoding else detected_encoding
        return java_fields_to_schema(class_name, fields, encoding=final_encoding)

    elif filepath.suffix == ".class":
        # Parse bytecode - can't auto-detect encoding from bytecode
        class_name, fields = parse_java_class(filepath)
        return java_fields_to_schema(class_name, fields, encoding=encoding)

    else:
        raise ValueError(f"Unsupported file type: {filepath.suffix}")


def merge_schemas(*schemas: Schema) -> Schema:
    """Merge multiple schemas into one.

    Args:
        *schemas: Schema objects to merge

    Returns:
        Merged Schema with all message types
    """
    merged = Schema()

    for schema in schemas:
        merged.messages.update(schema.messages)
        if schema.default_message and not merged.default_message:
            merged.default_message = schema.default_message

    return merged
